{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a698d26",
   "metadata": {},
   "source": [
    "# PySpark - Project Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264c5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f5fed",
   "metadata": {},
   "source": [
    "# Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033a5123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 22:31:27 WARN Utils: Your hostname, muhammad-Vm resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/04/25 22:31:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/25 22:31:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('project_tweets').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb78f71",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a61042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the ProjectTweets into Hadoop in the named folder 'CA2'\n",
    "\n",
    "data = spark.read.csv('hdfs://localhost:9000/CA2/ProjectTweets.csv', header=True, inferSchema =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structure of schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c534db",
   "metadata": {},
   "source": [
    "# Rename Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b08643",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50967eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = Row(*old_columns)(*old_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame([new_row], old_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = new_df.union(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfa24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeie as colunas\n",
    "new_column_names = [\"index\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df_renamed = combined_df.toDF(*new_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec4ba1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mostrar o DataFrame com as colunas renomeadas\n",
    "df_renamed.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém o número de linhas\n",
    "num_rows = df_renamed.count()\n",
    "print(f\"Número de linhas: {num_rows}\")\n",
    "\n",
    "# Obtém o número de colunas\n",
    "num_columns = len(df_renamed.columns)\n",
    "print(f\"Número de colunas: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bd476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_renamed.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aed9ff",
   "metadata": {},
   "source": [
    "# Split the dataset into Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9845dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into three parts\n",
    "train, validation, test  = data.randomSplit([0.7, 0.2, 0.1], 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98eb7a2",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2588a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e5fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ebee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
